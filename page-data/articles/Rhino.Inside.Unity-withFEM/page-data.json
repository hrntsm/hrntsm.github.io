{"componentChunkName":"component---src-templates-blog-post-js","path":"/articles/Rhino.Inside.Unity-withFEM","result":{"data":{"markdownRemark":{"html":"<p>　バーチャルモーションキャプチャーとRhino.Inside.Unityを使って以下の動画のような形で人型に対するリアルタイムでのFEM解析をやってみます。</p>\n<p><a href=\"https://1.bp.blogspot.com/-X7Wmy3d32-c/XmW2fkPcgWI/AAAAAAAAB0g/3LxrkN8GmLUOFBorIu-ZTqh_WuhJhyoDQCLcBGAsYHQ/s1600/VMCmoment.gif\"><img src=\"https://1.bp.blogspot.com/-X7Wmy3d32-c/XmW2fkPcgWI/AAAAAAAAB0g/3LxrkN8GmLUOFBorIu-ZTqh_WuhJhyoDQCLcBGAsYHQ/s320/VMCmoment.gif\"></a></p>\n<p>　大きな流れとしては、以下の形です。  </p>\n<ol>\n<li><a href=\"https://sh-akira.github.io/VirtualMotionCapture/\">バーチャルモーションキャプチャー</a>で機器からの情報を取得</li>\n<li><a href=\"https://github.com/gpsnmeajp/EasyVirtualMotionCaptureForUnity\">EVMC4U</a>を使ってバーチャルモーションキャプチャーからの情報をUnityに取得する</li>\n<li>Rhino.Inside.Unityで各ボーンの情報をRhinoに送る</li>\n<li>karambaでFEM解析</li>\n</ol>\n<p>　バーチャルモーションキャプチャー（以下ばもきゃ）とEVMC4Uについての詳細は、上記のリンクから各ソフトのHPでのそれぞれの説明を確認してください。<br>\n上記の動画ではVIVEとVIVEトラッカーを3つ使って頭、両手、腰、両足をトラッキングしながら撮影しています。</p>\n<p>　ばもきゃとEVMC4Uの接続については、<a href=\"https://github.com/gpsnmeajp/EasyVirtualMotionCaptureForUnity/wiki\">EVMC4Uのwiki</a>を参照してください。</p>\n<p>　ばもきゃとのやり取りでハマった箇所としては、ばもきゃとEVMC4UはOSCで情報のやり取りをしていますが、送られているボーン位置の情報はローカル座標で送らている点です。最初はグローバルの座標で送られていると思いそのまま座標をRhinoに送ろうとしていましたが、ローカル座標のためボーンが意味不明な位置になってしまい結構悩みました。  </p>\n<p>　ここから今回のために変更した個所の説明をします。<br>\nEVMC4Uを使える段階にするとExternalReceiver.csを使って情報をばもきゃから受信する形になっていると思います。ここにRhinoへボーン情報を送信用の部分を以下の18行目からの個所のように追記しています。ExternalReceiver.cs全体でいうと576行目くらいから始まる private void BoneSynchronizeSingle の個所になります。</p>\n<p>　ここではばもきゃから受信したボーンの各点の座標を各ボーンに適用しているので、その値を取得し対象のボーンの名前とポジションを GrasshopperInUnity.SendBonePosition の引数として入力します。途中の長い if文は今回必要なボーンだけを設定するように場合分けしているだけなので、必要に応じて修正してください。  </p>\n<p>　次にGrasshopperInUnityについてです。ここでは参考として<a href=\"https://github.com/mcneel/rhino.inside/tree/master/Unity/Sample2\">Rhino.Inside.Unityのサンプル2</a>を使用しているので、そこからの追記箇所についての説明になります。追記したものは以下です。  </p>\n<p>　最初の動作だった場合(_firstRunがTrue)は、grasshopperを起動させ、Unityをいったんポーズの状態にします。ポーズにする理由は、grasshopperを起動後、.ghファイルを選択し開くまでの間はUnityが止まっていないとRhino.Inside.Unityでの送り先がなくエラーになってしまうからです。<br>\n6行目以降はボーンの座標をargsにセットしてgrasshopper側で受け取れるようにしています。<br>\nこれで各ボーンの頂点データがgrasshopper側で受け取れるようになったので、あとはその点を使って骨組みを作りkarambaで解析します。<br>\n一連の説明は以上ですが、冒頭の動画のようにこの動作は非常に重いので、もう少し高速化できたら楽しそうなのですが、それは今後の課題です。</p>","excerpt":"バーチャルモーションキャプチャーとRhino.Inside.Unityを使って以下の動画のような形で人型に対するリアルタイムでのFEM解析をやってみます。  　大きな流れとしては、以下の形です。   バーチャルモーションキャプチャーで機器からの情報を取得 EVMC4U…","frontmatter":{"date":"09 March, 2020","path":"/articles/Rhino.Inside.Unity-withFEM","title":"RhinoInside を使ってリアルタイムで人の動きのFEM解析をやってみる","tags":["karamba","Unity","VR","RhinoInside","C#"]},"fields":{"readingTime":{"text":"1 min read"},"slug":"/Rhino.Inside.Unity-withFEM/","collection":"article"}}},"pageContext":{}},"staticQueryHashes":["3649515864","63159454"]}