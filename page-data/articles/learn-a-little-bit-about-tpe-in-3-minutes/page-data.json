{"componentChunkName":"component---src-templates-article-post-js","path":"/articles/learn-a-little-bit-about-tpe-in-3-minutes","result":{"data":{"markdownRemark":{"html":"<h2>はじめに</h2>\n<p>Grasshopper で使用できる最適化コンポーネント Tunny を開発しています。</p>\n<ul>\n<li><a href=\"https://www.food4rhino.com/en/app/tunny\">food 4 Rhino - Tunny</a></li>\n</ul>\n<p>その中でベイズ最適化や進化戦略、準モンテカルロなどこれまでの Grasshopper の最適化コンポーネントでなじみのないアルゴリズムがあります。\nそれらを使うにあたってざっくりとしたアルゴリズムへの理解があるとより使いやすくなるため、簡単な紹介をします。</p>\n<p>ここでの内容は Tunny の公式ドキュメントの <a href=\"https://tunny-docs.deno.dev/docs/technical-info\">Technical Info</a> を翻訳したものがベースになります。</p>\n<p>この記事では TPE という手法について紹介します。\nアルゴリズムのざっくりとした理解を目的にしており、正確でない可能性があります。\n詳細は最後に掲載している参考文献を確認してください。</p>\n<h2>Tree-structured Parzen Estimator(TPE)</h2>\n<p>TPE はベイズ最適化に分類される手法です。\nベイズ最適化で検索すると TPE よりもガウス過程（GaussianProcess, GP）を使ったものが多くヒットします。\nここでは簡単にそれらの相違点の概要を以下に示します。</p>\n<ul>\n<li>\n<p>GP は <code class=\"language-text\">p(y|x)</code> を使って期待改善量(ExpectedImprovement, EI)を計算します。</p>\n<ul>\n<li>観測点から事後分布を計算し、それを使用して次の探索点を決定します。</li>\n<li>GP を実行する過程で逆行列計算があるため、時間オーダーは <code class=\"language-text\">O(n^3)</code> になります。</li>\n</ul>\n</li>\n<li>\n<p>TPE は <code class=\"language-text\">p(x|y)</code> と <code class=\"language-text\">p(y)</code> を使用して EI を計算します。</p>\n<ul>\n<li>y の事後分布 p(y|x) は必要ありません。</li>\n<li>1 変数当たりの TPE の時間計算量は O(nlogn) です。これは、y を y∗ の値で 2 分割することに関連して値をソートする必要があるためです。</li>\n<li>各変数は (多変量ではなく) 独立していると想定されるため、全体の時間オーダーは上記に変数の数 d をかけて <code class=\"language-text\">O(dnlogn)</code> になります。</li>\n</ul>\n</li>\n</ul>\n<h3>TPE のアルゴリズムについて</h3>\n<p>このセクションでは実際の TPE の動作について説明します。\n以下の STEP2 ～ STEP3 を繰り返し実行することで、TPE は最適化を行います。</p>\n<h4>ステップ 1</h4>\n<p>Tunny のデフォルト設定では、はじめに目的関数の代理モデル（サロゲートモデル）を作成するため、ランダムサンプリングが実行されます。\nここでは、次の関数の最小化問題を例に解いていきます。</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-text line-numbers\"><code class=\"language-text\">y = exp(x)*sin(3πx)\n-1 &lt; x &lt; 1</code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span></span></pre></div>\n<p>サンプリングした結果は以下です。\n図中の ★ はサンプリングされた点です。</p>\n<img src=\"https://tunny-docs.deno.dev/docs/technical-info/tpe1.png\">\n<h4>ステップ 2</h4>\n<p>得られたサンプリング点を <code class=\"language-text\">l(x)</code> と <code class=\"language-text\">g(x)</code> の 2 つに分割します。\nTunny は分割するとき、<code class=\"language-text\">y*</code> というある値で分割します。\n<code class=\"language-text\">y*</code> は上位 10％ の個体または 25 個体の小さい方で分割する値になります。</p>\n<p>次の例では <code class=\"language-text\">y*=-0.83</code> となり、この値を使ってサンプリングされた点を <code class=\"language-text\">l(x)</code> と <code class=\"language-text\">g(x)</code> に 2 分します。</p>\n<img src=\"https://tunny-docs.deno.dev/docs/technical-info/tpe2.png\">\n<h4>ステップ 3</h4>\n<p>次に、l(x) と g(x) のそれぞれに対してカーネル密度推定 (KernelDensityEstimator, KDE) を実行します。\nKDE は、滑らかな曲線で表現された値のヒストグラムと考えることができます。次の図の棒グラフは l(x) と g(x) のヒストグラムを示し、曲線は KDE の結果です。</p>\n<p>KDE によって推定される l(x) は、上位の個体 (つまり値が小さい個体) を得られる確率が高い x の値と考えることができます。\n同様に g(x) は、下位の個体 (つまり値が小さい個体) を得られる確率が高い x の値と考えることができます。</p>\n<p>TPE では、l(x) と g(x) の比 l(x)/g(x) が最大となる x を見つけることによって、次の探索点が決定されます。\nこの例では、<code class=\"language-text\">x=0.455</code> になります。</p>\n<p>l(x)/g(x) を最大化する点を探すことは上記の説明から、最も値が小さい個体を取得する確率が高く、かつ値が大きい個体を取得する確率が小さい点を TPE が計算することを意味します。</p>\n<img src=\"https://tunny-docs.deno.dev/docs/technical-info/tpe3.png\">\n<p>KDE は、TPE の「PE」部分の由来である Parzen Estimator としても知られています。</p>\n<h4>注意事項</h4>\n<p>STEP 1 はランダムサンプリングを行っており、このステップは非常に重要です。\nTunny はデフォルトで 10 ポイントをサンプリングします。\nあなたが実行しようとしている最適化にこの数が適しているかどうかを常に考えてください。\n参考文献にあげている TPE 論文では次の数値を推奨しています。</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-text line-numbers\"><code class=\"language-text\">変数の数 × 11 - 1</code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span></span></pre></div>\n<p>十分なサンプリングがないと、KDE ​​ は適切に実行されず、次の検索ポイントを効率的に見つけることができません。\n例として、上記で実行したサンプル数の半分だけを取得した場合の結果を次に示します。</p>\n<img src=\"https://tunny-docs.deno.dev/docs/technical-info/tpe4.png\">\n<img src=\"https://tunny-docs.deno.dev/docs/technical-info/tpe5.png\">\n<p>この例では十分にサンプリングされていないため、次の検索ポイントは <code class=\"language-text\">x=-0.434</code> と計算されます。\nこれは、大域的最適解が存在する <code class=\"language-text\">x=0.5</code> 付近の値とはまったく異なります。</p>\n<img src=\"https://tunny-docs.deno.dev/docs/technical-info/tpe6.png\">\n<p>適度な数をサンプリングしないと適切に次の探索点を求める計算が出来ず、最適化がうまくすすまないことに注意してください。</p>\n<h2>参考文献</h2>\n<ul>\n<li><a href=\"https://qiita.com/narrowlyapplicable/items/65ad761b28f7ff53ef23\">Optunaの基幹アルゴリズム＝TPESamplerを読む</a></li>\n<li><a href=\"http://neupy.com/2016/12/17/hyperparameter_optimization_for_neural_networks.html#tree-structured-parzen-estimators-tpe\">Hyperparameter optimization for Neural Networks #TPE</a></li>\n<li><a href=\"https://proceedings.neurips.cc/paper/2011/file/86e8f7ab32cfd12577bc2619bc635690-Paper.pdf\">Algorithms for Hyper-Parameter Optimization</a></li>\n<li><a href=\"http://proceedings.mlr.press/v28/bergstra13.pdf\">Making a Science of Model Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures</a></li>\n</ul>","excerpt":"はじめに Grasshopper で使用できる最適化コンポーネント Tunny を開発しています。 food 4 Rhino - Tunny その中でベイズ最適化や進化戦略、準モンテカルロなどこれまでの Grasshopper…","frontmatter":{"date":"08 October, 2022","path":"/articles/learn-a-little-bit-about-tpe-in-3-minutes","title":"3分でちょっとだけわかる TPE","article_tags":["Grasshopper","Tunny"]},"fields":{"readingTime":{"text":"2 min read"},"slug":"/learn-a-little-bit-about-tpe-in-3-minutes/","collection":"article"}},"site":{"siteMetadata":{"title":"構造とデジタル_最新版_Final(1)"}}},"pageContext":{}},"staticQueryHashes":["32046230","3649515864"]}